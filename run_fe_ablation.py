#!/usr/bin/env python3
"""
è¿è¡ŒFE-IDDQNæ¶ˆèå®éªŒ
å¯¹æ¯”ä¸åŒç‰¹å¾é…ç½®ä¸‹FE-IDDQN vs HEFTçš„æ€§èƒ½
"""

import os
import subprocess
from pathlib import Path
import pandas as pd
import numpy as np

ROOT = Path(__file__).parent
VAL = ROOT / 'val_data_20250930_122033_labeled.csv'
OUT_DIR = ROOT / 'ablation_fe'
OUT_DIR.mkdir(exist_ok=True)

# æ¶ˆèå®éªŒå˜ä½“
VARIANTS = {
    'BASE': {
        'STRICT_HIST_DUR': '0',
        'FE_ENHANCED': '1',
        'EF_COEF': '3e-4',
        'HEFT_COEF': '0.15',
        'DISP_COEF': '1e-5',
        'FE_NO_TTYPE': '0',
        'FE_IGNORE_Q': '0'  # ç¡®ä¿è¿è¡ŒFE-IDDQN
    },
    '-A_no_speed': {
        'STRICT_HIST_DUR': '1',  # å…³é—­speed_factor
        'FE_ENHANCED': '1',
        'EF_COEF': '3e-4',
        'HEFT_COEF': '0.15',
        'DISP_COEF': '1e-5',
        'FE_NO_TTYPE': '0',
        'FE_IGNORE_Q': '0'
    },
    '-B_no_upward': {
        'STRICT_HIST_DUR': '0',
        'FE_ENHANCED': '1',
        'EF_COEF': '3e-4',
        'HEFT_COEF': '0.0',      # å…³é—­upward_rank
        'CP_COEF': '0.0',
        'DISP_COEF': '1e-5',
        'FE_NO_TTYPE': '0',
        'FE_WARM_HEFT': '0',
        'FE_IGNORE_Q': '0'
    },
    '-C_no_ttype': {
        'STRICT_HIST_DUR': '0',
        'FE_ENHANCED': '1',
        'EF_COEF': '3e-4',
        'HEFT_COEF': '0.15',
        'DISP_COEF': '1e-5',
        'FE_NO_TTYPE': '1',      # å…³é—­ä»»åŠ¡ç±»å‹ç‰¹å¾
        'FE_IGNORE_Q': '0'
    }
}

def run_one(pid: int, env: dict, variant_label: str):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    env_str = ' '.join([f"{k}={v}" for k, v in env.items()])
    metrics_file = OUT_DIR / f"metrics_{pid}_{variant_label}.csv"
    
    cmd = f"source .venv/bin/activate && {env_str} python create_gantt_chart_generic.py {pid} > /dev/null 2>&1"
    
    print(f"    è¿è¡Œ {pid}...", end='', flush=True)
    result = subprocess.run(cmd, shell=True, cwd=str(ROOT))
    
    # æ£€æŸ¥ç»“æœ
    orig_metrics = ROOT / f"metrics_{pid}.csv"
    if orig_metrics.exists():
        import shutil
        shutil.move(str(orig_metrics), str(metrics_file))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰FE_IDDQNæ•°æ®
        try:
            df = pd.read_csv(metrics_file)
            if 'FE_IDDQN' in df['algorithm'].values:
                print(f" âœ…")
                return True
            else:
                print(f" âš ï¸ (æ²¡æœ‰FE_IDDQN)")
                return False
        except:
            print(f" âŒ (è¯»å–å¤±è´¥)")
            return False
    else:
        print(f" âŒ (æ— æ–‡ä»¶)")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¼€å§‹FE-IDDQNæ¶ˆèå®éªŒ")
    print("="*80)
    
    # è¯»å–éªŒè¯æ•°æ®
    df = pd.read_csv(VAL)
    
    # æ”¹ç”¨XLargeè§„æ¨¡ï¼ˆä»»åŠ¡æ•°æ›´å¤šï¼Œä¸ä¼šè§¦å‘å°è§„æ¨¡å¤„ç†ï¼‰
    xlarge_pids = df[df['size'] == 'XLarge']['process_id'].unique()[:12]  # XLargeæœ‰12ä¸ª
    print(f"\nğŸ“‹ XLargeè§„æ¨¡å·¥ä½œæµ: {len(xlarge_pids)} ä¸ª")
    print(f"Process IDs: {list(xlarge_pids)}\n")
    
    all_results = []
    
    for variant_name, env in VARIANTS.items():
        variant_label = f"XLarge{variant_name}"
        print(f"\nğŸ§ª è¿è¡Œå˜ä½“: {variant_label}")
        print(f"é…ç½®: {env}")
        print("-"*80)
        
        success_count = 0
        for pid in xlarge_pids:
            if run_one(int(pid), env, variant_label):
                success_count += 1
        
        print(f"\nâœ… æˆåŠŸ: {success_count}/{len(xlarge_pids)}")
        
        # æ”¶é›†ç»“æœ
        variant_results = []
        for pid in xlarge_pids:
            metrics_file = OUT_DIR / f"metrics_{int(pid)}_{variant_label}.csv"
            if metrics_file.exists():
                try:
                    df_m = pd.read_csv(metrics_file)
                    df_m['variant'] = variant_label
                    df_m['variant_name'] = variant_name
                    variant_results.append(df_m)
                except:
                    pass
        
        if variant_results:
            all_results.append(pd.concat(variant_results, ignore_index=True))
    
    if not all_results:
        print("\nâŒ æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•ç»“æœ")
        return
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    results_df = pd.concat(all_results, ignore_index=True)
    
    # ä¿å­˜åŸå§‹æ•°æ®
    out_csv = OUT_DIR / 'fe_ablation_results.csv'
    results_df.to_csv(out_csv, index=False)
    print(f"\nğŸ’¾ åŸå§‹æ•°æ®ä¿å­˜åˆ°: {out_csv}")
    
    # åˆ†æç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š åˆ†æFE-IDDQNæ¶ˆèå®éªŒç»“æœ")
    print("="*80)
    
    # åªä¿ç•™HEFTå’ŒFE_IDDQN
    df_compare = results_df[results_df['algorithm'].isin(['HEFT', 'FE_IDDQN'])].copy()
    
    if len(df_compare) == 0:
        print("âŒ æ²¡æœ‰å¯å¯¹æ¯”çš„æ•°æ®")
        return
    
    # æŒ‰å·¥ä½œæµå’Œå˜ä½“åˆ†ç»„ï¼Œè®¡ç®—æ”¹è¿›
    pivot = df_compare.pivot_table(
        index=['process_id', 'variant_name'],
        columns='algorithm',
        values='makespan',
        aggfunc='min'
    ).reset_index()
    
    # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
    pivot['improve_vs_heft'] = (pivot['HEFT'] - pivot['FE_IDDQN']) / pivot['HEFT']
    
    # æŒ‰å˜ä½“åˆ†ç»„ç»Ÿè®¡
    summary = pivot.groupby('variant_name')['improve_vs_heft'].agg([
        'count', 'mean', 'std', 'median'
    ]).reset_index()
    
    summary['mean_pct'] = summary['mean'] * 100
    summary['std_pct'] = summary['std'] * 100
    summary['median_pct'] = summary['median'] * 100
    
    # ä¿å­˜æ±‡æ€»
    summary_file = OUT_DIR / 'fe_ablation_summary.csv'
    summary.to_csv(summary_file, index=False)
    print(f"ğŸ’¾ æ±‡æ€»æ•°æ®ä¿å­˜åˆ°: {summary_file}")
    
    # æ‰“å°è¡¨5.8
    print("\n" + "="*80)
    print("ğŸ“ è¡¨5.8 ç‰¹å¾å·¥ç¨‹æ¶ˆèå®éªŒç»“æœï¼ˆXLargeè§„æ¨¡ï¼‰")
    print("="*80)
    print("\n| ç‰¹å¾é›† | å¹³å‡æ”¹è¿›(%) | æ ‡å‡†å·®(%) | å·¥ä½œæµæ•°é‡ | ä¸­ä½æ•°(%) |")
    print("|--------|------------|----------|-----------|-----------|")
    
    variant_labels = {
        'BASE': 'XLargeBASE (å®Œæ•´ç‰¹å¾)',
        '-A_no_speed': 'XLarge-A (å»é™¤speed_factor)',
        '-B_no_upward': 'XLarge-B (å»é™¤upward_rank)',
        '-C_no_ttype': 'XLarge-C (å»é™¤ä»»åŠ¡ç±»å‹)'
    }
    
    for _, row in summary.iterrows():
        label = variant_labels.get(row['variant_name'], row['variant_name'])
        print(f"| {label:30} | {row['mean_pct']:>10.1f} | {row['std_pct']:>8.1f} | "
              f"{int(row['count']):>9d} | {row['median_pct']:>9.1f} |")
    
    # è¯¦ç»†åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“ˆ è¯¦ç»†åˆ†æ")
    print("="*80)
    
    for variant in ['BASE', '-A_no_speed', '-B_no_upward', '-C_no_ttype']:
        variant_data = pivot[pivot['variant_name'] == variant]
        if len(variant_data) > 0:
            improvements = variant_data['improve_vs_heft'] * 100
            print(f"\n{variant}:")
            print(f"  æ ·æœ¬æ•°: {len(improvements)}")
            print(f"  å¹³å‡æ”¹è¿›: {improvements.mean():.1f}%")
            print(f"  æ ‡å‡†å·®: {improvements.std():.1f}%")
            print(f"  ä¸­ä½æ•°: {improvements.median():.1f}%")
            print(f"  æœ€å°å€¼: {improvements.min():.1f}%")
            print(f"  æœ€å¤§å€¼: {improvements.max():.1f}%")
            print(f"  25åˆ†ä½: {improvements.quantile(0.25):.1f}%")
            print(f"  75åˆ†ä½: {improvements.quantile(0.75):.1f}%")
    
    print("\nâœ… æ¶ˆèå®éªŒå®Œæˆ!")

if __name__ == '__main__':
    main()

